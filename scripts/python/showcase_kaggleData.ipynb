{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% Date 03.01.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcase of kaggleData.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the title says, this is only a showcase.  \n",
    "For actual documentation, refer to kaggleData.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import kaggleData as kD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important for working with the original Kaggle datasets is recreating them.  \n",
    "Keep in mind, that the file `atlas-higgs-challenge-2014-v2.csv`\n",
    " is needed in the data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we extract the whole csv file into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_data,csv_header = kD.csvToArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to extract all information we want form this data, this includes the data necessary to reproduce the AMS rating performed by Kaggle.\n",
    "The data sets we extract are\n",
    "* training set\n",
    "* test set\n",
    "* solution set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data,train_header,test_data,test_header=kD.getOriginalKaggleSets(csv_data,csv_header)\n",
    "sol_data,sol_header = kD.getSolutionKey(csv_data,csv_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to prepare the sets further to avoid errors in classification. For most, that means we need to cut certain arrays and translate data into other datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = train_data[:,1:-2].astype(float)\n",
    "train_labels = kD.translateLabels(train_data[:,-1],[\"Label\"]).astype(float)\n",
    "train_weights = train_data[:,-2].astype(float)\n",
    "test_all = test_data[:,1:].astype(float)\n",
    "header_all = test_header[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract single and multiple features as array. For instance we need to save the list of event IDs of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_events = kD._extractFeature(\"EventId\",test_data,csv_header).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract multiple features as we create feature subsets, like listed in Tab. 3 of the thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header_1 = [\"DER_mass_MMC\",\n",
    "            \"DER_mass_transverse_met_lep\",\n",
    "            \"DER_mass_vis\",\n",
    "            \"DER_met_phi_centrality\",\n",
    "            \"DER_pt_ratio_lep_tau\",\n",
    "            \"PRI_tau_pt\",\n",
    "            \"DER_pt_h\"]\n",
    "train_1 = kD._extractFeatures(header_1,train_data,train_header).astype(float)\n",
    "test_1 = kD._extractFeatures(header_1,test_data,test_header).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convinience, arrays for a feature set can be received directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header_2,train_2,test_2 = kD.getFeatureSubset(train_data,test_data,train_header,test_header,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily access the Kaggle leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pubLB,privLB = kD.getLeaderBoards()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leaderboard data is saved in the order [user ID, score, rank] and sorted with respect to the ranks.  \n",
    "For comparing private and public leaderboards effectively, the data needs to be sorted w.r.t. the user IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import toolbox as tb\n",
    "sortedPriv=tb.sortByColumn(privLB,0)\n",
    "sortedPub=tb.sortByColumn(pubLB,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we can access any Kaggle leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pubLB,privLB = kD.getLeaderBoards(\"https://www.kaggle.com/c/flavours-of-physics/leaderboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use an url of a running competition, we still receive data of the public leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaderboard-URL not found.\n",
      "Private Leaderboard has not been found, is the competition still running?\n",
      "Use getLeaderBoard(url) for a single leaderboard.\n"
     ]
    }
   ],
   "source": [
    "pubLB,privLB = kD.getLeaderBoards(\"https://www.kaggle.com/c/home-depot-product-search-relevance/leaderboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  2.66169000e+05,   4.48480000e-01,   1.00000000e+00],\n",
       "        [  2.65984000e+05,   4.49040000e-01,   2.00000000e+00],\n",
       "        [  2.67747000e+05,   4.50310000e-01,   3.00000000e+00],\n",
       "        ..., \n",
       "        [  2.82540000e+05,   1.47868000e+00,   1.33300000e+03],\n",
       "        [  2.83664000e+05,   1.47868000e+00,   1.33400000e+03],\n",
       "        [  2.69043000e+05,   1.47872000e+00,   1.33500000e+03]]), None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubLB,privLB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
