{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%Date: 07.01.2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import linear_model as linMod\n",
    "import toolbox as tb;\n",
    "import kaggleData as kD;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate toydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#toydata shall have n vectors with 5 dimensions\n",
    "n = 100000\n",
    "#probability for signal-label\n",
    "s_prob = 0.05\n",
    "dim = 4\n",
    "data = tb.createToyData(n,dim,s_prob)\n",
    "weights = data[:,0]\n",
    "labels = data[:,1]\n",
    "x_1 = data[:,2]\n",
    "x_2 = data[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.scatter(x_1, x_2, edgecolor=\"\", c=labels, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split toydata into training- and testset for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_train = int(n/10)\n",
    "\n",
    "train_x_1,test_x_1 = tb.splitList(x_1,n_train)\n",
    "train_x_2,test_x_2 = tb.splitList(x_2,n_train)\n",
    "train_labels,test_labels = tb.splitList(labels,n_train)\n",
    "test_weights = tb.splitList(weights,n_train)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Comparison, we calculate the best possible AMS    \n",
    "(case: every signal correctly detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb.calcMaxAMS(test_weights,test_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we initialize the Logistic Regression Classifier, shape the input-data and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logReg = linMod.LogisticRegression(C=1e5)\n",
    "\n",
    "train_x = np.array([train_x_1,train_x_2]).transpose()\n",
    "test_x = np.array([test_x_1,test_x_2]).transpose()\n",
    "train_labels = np.array(train_labels).transpose()\n",
    "test_labels = np.array(test_labels).transpose()\n",
    "\n",
    "logReg.fit(train_x,train_labels)\n",
    "\n",
    "logReg.sparsify()\n",
    "\n",
    "predProb = logReg.predict_proba(test_x)\n",
    "pred = logReg.predict(test_x)\n",
    "score = logReg.score(test_x,test_labels)\n",
    "\n",
    "print(\"Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s,b = tb.calcWeightSums(test_weights,pred,test_labels)\n",
    "print(\"AMS:\",tb.calcAMS(s,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully tested logistic Regression, now let's use it on actual CERN-Data.           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(header,\n",
    " test_data,\n",
    " test_weights,\n",
    " test_labels,\n",
    " train_data,\n",
    " train_weights,\n",
    " train_labels) = kD.getWholeDataSet(kSet=[\"b\",\"v\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainingset has key \"t\"                   \n",
    "Public Testset has key \"b\"   \n",
    "Private Testset has key \"v\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_eventList,test_eventList = kD.getFeatureSets(\"EventId\",header,test_data,train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are labels and weights related?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signal_sum = int(test_labels.cumsum()[-1])\n",
    "background_sum = int(len(test_labels)-signal_sum)\n",
    "signal_weight = 0\n",
    "background_weight = 0\n",
    "for i in range(0,len(test_labels)):\n",
    "    if test_labels[i] > 0:\n",
    "        signal_weight += test_weights[i]\n",
    "    else:\n",
    "        background_weight += test_weights[i]\n",
    "print(\"Mean of background-weights:\", background_weight/background_sum)\n",
    "print(\"Mean of signal-weights:\",signal_weight/signal_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that False signals are weighted a lot heavier than True signals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a classifier achieved a higher AMS while detecting less signals,   \n",
    "we can make statements about the usabilty of the features, the classifier used.\n",
    "\n",
    "We choose features with beneficial properties for classifying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_DER_met_phi_centrality,\n",
    " test_DER_met_phi_centrality) = kD.getFeatureSets(\"DER_met_phi_centrality\",header,test_data,train_data)\n",
    "(train_DER_pt_ratio_lep_tau,\n",
    " test_DER_pt_ratio_lep_tau) = kD.getFeatureSets(\"DER_pt_ratio_lep_tau\",header,test_data,train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using DER_mass_MMC was not allowed in the former contest, we use it here anyway to test our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_DER_mass_MMC,\n",
    " test_DER_mass_MMC) = kD.getFeatureSets(\"DER_mass_MMC\",header,test_data,train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels).transpose()\n",
    "test_labels = np.array(test_labels).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb.calcMaxAMS(test_weights,test_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with one feature and add more with every regression to see improvement of the AMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logisticReg(train_x,train_labels,test_x,test_labels):\n",
    "    logReg = None\n",
    "    logReg = linMod.LogisticRegression()\n",
    "    logReg.fit(train_x,train_labels)\n",
    "    logReg.sparsify()\n",
    "    predProb = logReg.predict_proba(test_x)\n",
    "    pred = logReg.predict(test_x)\n",
    "    signals = int(pred.cumsum()[-1])  \n",
    "    return predProb,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logRegFor(fList):\n",
    "    for feature in fList:\n",
    "        print(\"Feature:\",feature)\n",
    "        trainList_x,testList_x = kD.getFeatureSets(feature)\n",
    "        train_x = np.array([trainList_x]).transpose()\n",
    "        test_x = np.array([testList_x]).transpose()\n",
    "        logisticReg(train_x,train_labels,test_x,test_labels)[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_PRI_tau_pt,\n",
    " test_PRI_tau_pt) = kD.getFeatureSets(\"PRI_tau_pt\",header,test_data,train_data)\n",
    "(train_DER_met_phi_centrality,\n",
    " test_DER_met_phi_centrality) = kD.getFeatureSets(\"DER_met_phi_centrality\",header,test_data,train_data)\n",
    "(train_DER_pt_h,\n",
    " test_DER_pt_h) = kD.getFeatureSets(\"DER_pt_h\",header,test_data,train_data)\n",
    "(train_DER_pt_ratio_lep_tau,\n",
    " test_DER_pt_ratio_lep_tau) = kD.getFeatureSets(\"DER_pt_ratio_lep_tau\",header,test_data,train_data)\n",
    "(train_DER_mass_transverse_met_lep,\n",
    " test_DER_mass_transverse_met_lep) = kD.getFeatureSets(\"DER_mass_transverse_met_lep\",header,test_data,train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to achieve a higher AMS by adjusting the decision-threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customThreshold(pred,t = 0.5):\n",
    "    newPred = np.zeros(len(pred))\n",
    "    for i in range(0,len(pred)):\n",
    "        if pred[i] > t:\n",
    "            newPred[i]=1\n",
    "    return newPred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bestThreshold(predProb,test_weights,test_labels):\n",
    "    bestPred = predProb\n",
    "    thresh = 0\n",
    "    maxAMS = 0\n",
    "    maxThresh = 0\n",
    "    newSignals = 0\n",
    "    for thresh in np.linspace(1.0,0.0,100):\n",
    "        newPred = customThreshold(predProb,thresh)\n",
    "        s,b = tb.calcWeightSums(test_weights,newPred,test_labels)\n",
    "        #print(\"s:\",s,\"b:\",b)\n",
    "        ams = tb.calcAMS(s,b)\n",
    "        #print(\"ams:\",ams)\n",
    "        if ams > maxAMS:\n",
    "            bestPred = newPred\n",
    "            maxThresh = thresh\n",
    "            maxAMS = ams\n",
    "            newSignals = int(newPred.cumsum()[-1])\n",
    "    #print(\"Maximum AMS:\",maxAMS, \"with threshold\", maxThresh)\n",
    "    #print(\"Signals read:\", newSignals)\n",
    "    return bestPred,maxAMS,maxThresh,newSignals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compareBinaryArrays(a,b):\n",
    "    if np.shape(a) != np.shape(b):\n",
    "        print(\"ERROR: Arrays must have same shape.\")\n",
    "        return None\n",
    "    eq_total = 0\n",
    "    eq_ones = 0\n",
    "    eq_zeros = 0\n",
    "    for i in range(0,len(a)):\n",
    "        if a[i] == b[i]:\n",
    "            eq_total += 1\n",
    "            if a[i] == 1:\n",
    "                eq_ones += 1\n",
    "            else:\n",
    "                eq_zeros += 1\n",
    "    return eq_total,eq_ones,eq_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fullEvaluation(predProb,pred,test_weights,test_labels):\n",
    "    signals = pred.cumsum()[-1]\n",
    "    correct = np.equal(pred,test_labels).cumsum()[-1]    \n",
    "    s,b = tb.calcWeightSums(test_weights,pred,test_labels)\n",
    "    ams = tb.calcAMS(s,b)\n",
    "   \n",
    "    newPred,maxAMS,maxThresh,newSignals = bestThreshold(predProb[:,1],test_weights,test_labels)\n",
    "    newcorrect = np.equal(newPred,test_labels).cumsum()[-1]\n",
    "    \n",
    "    T_eq1,T_eq0 = compareBinaryArrays(test_labels,test_labels)[1:]\n",
    "    o_eqt,o_eq1,o_eq0 = compareBinaryArrays(pred,test_labels)\n",
    "    a_eqt,a_eq1,a_eq0 = compareBinaryArrays(newPred,test_labels)\n",
    "    \n",
    "    print(\"Signals in test-data:\", test_labels.cumsum()[-1])\n",
    "    print(\"Comparison of [o]riginal and [a]djusted predictions:\\n\"+\n",
    "          \" - [o]Signals read:\", signals,\"\\n\"+\n",
    "          \" - [a]Signals read:\", newSignals,\"\\n\"+\n",
    "          \" -- Difference:\", (signals-newSignals),\"\\n\"+\n",
    "          \" - [o]Correct labels:\", o_eqt,\"| signals:\", o_eq1,\"| background:\",o_eq0,\"\\n\"+\n",
    "          \" ----- wrong signals:\", (T_eq1-o_eq1), \"| background:\", (T_eq0-o_eq0),\"\\n\"+\n",
    "          \" - [a]Correct labels:\", a_eqt,\"| signals:\", a_eq1,\"| background:\",a_eq0,\"\\n\"+\n",
    "          \" ----- wrong signals:\", (T_eq1-a_eq1), \"| background:\", (T_eq0-a_eq0),\"\\n\"+\n",
    "          \" -- Difference labels:\", (a_eqt-o_eqt),\"| signals:\", (a_eq1-o_eq1),\"| background:\",(a_eq0-o_eq0),\"\\n\"+\n",
    "          \" - [o]AMS:\", ams,\"\\n\"+\n",
    "          \" - [a]AMS:\", maxAMS,\"(threshold =\",maxThresh,\")\\n\"+\n",
    "          \" -- Difference:\", (ams-maxAMS),\"\\n\"\n",
    "         )\n",
    "    return pred,newPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = np.array(\n",
    "    [train_PRI_tau_pt,\n",
    "     train_DER_met_phi_centrality,\n",
    "     train_DER_pt_h,\n",
    "     train_DER_pt_ratio_lep_tau]).transpose()\n",
    "test_X = np.array(\n",
    "    [test_PRI_tau_pt,\n",
    "     test_DER_met_phi_centrality,\n",
    "     test_DER_pt_h,\n",
    "     test_DER_pt_ratio_lep_tau]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS: 1.8693410466451816\n"
     ]
    }
   ],
   "source": [
    "logReg = linMod.LogisticRegression()\n",
    "logReg.fit(train_X,train_labels)\n",
    "logReg.sparsify()\n",
    "predProb = logReg.predict_proba(test_X)\n",
    "pred = logReg.predict(test_X)\n",
    "signals = int(pred.cumsum()[-1])  \n",
    "\n",
    "s,b = tb.calcWeightSums(test_weights,pred,test_labels)\n",
    "ams = tb.calcAMS(s,b)\n",
    "print(\"AMS:\", ams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals in test-data: 187708.0\n",
      "Comparison of [o]riginal and [a]djusted predictions:\n",
      " - [o]Signals read: 107786.0 \n",
      " - [a]Signals read: 343589 \n",
      " -- Difference: -235803.0 \n",
      " - [o]Correct labels: 385614 | signals: 65554 | background: 320060 \n",
      " ----- wrong signals: 122154 | background: 42232 \n",
      " - [a]Correct labels: 330731 | signals: 156014 | background: 174717 \n",
      " ----- wrong signals: 31694 | background: 187575 \n",
      " -- Difference labels: -54883 | signals: 90460 | background: -145343 \n",
      " - [o]AMS: 1.8693410466451816 \n",
      " - [a]AMS: 2.0063041235163688 (threshold = 0.242424242424 )\n",
      " -- Difference: -0.13696307687118714 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "(predProb,\n",
    " pred) = logisticReg(\n",
    "    train_X,\n",
    "    train_labels,\n",
    "    test_X,\n",
    "    test_labels);\n",
    "fullEvaluation(predProb,pred,test_weights,test_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tb.createSolutionFile(test_eventList,predProb[:,1],0.43,\"F:\\BA_git\\Data\\Solutions\\solution_logReg_test_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"[o] correct signal/correct labels:\",(53744/315491))\n",
    "print(\"[o] correct background/correct labels:\",(261747/315491))\n",
    "print(\"[a] correct signal/correct labels:\",(124621/275182))\n",
    "print(\"[a] correct background/correct labels:\",(150561/275182))\n",
    "print(\"\")\n",
    "print(\"[o] wrong signal/wrong labels:\",(99939/(len(test_labels)-315491)))\n",
    "print(\"[o] wrong background/wrong labels:\",(34570/(len(test_labels)-315491)))\n",
    "print(\"[a] wrong signal/wrong labels:\",(29062/(len(test_labels)-275182)))\n",
    "print(\"[a] wrong background/wrong labels:\",(145756/(len(test_labels)-275182)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adjusting the threshold, we raise the rate of correct signals at the expense of correctly predicted background-events.\n",
    "This results in a higher AMS even though we softened our decision-threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = np.array(\n",
    "    [train_DER_met_phi_centrality,\n",
    "     train_DER_pt_ratio_lep_tau]).transpose()\n",
    "test_x = np.array(\n",
    "    [test_DER_met_phi_centrality,\n",
    "     test_DER_pt_ratio_lep_tau]).transpose()\n",
    "predProb,pred = logisticReg(\n",
    "    train_x,train_labels,\n",
    "    test_x,\n",
    "    test_labels);\n",
    "fullEvaluation(predProb,pred,test_weights,test_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all but events, pls\n",
    "train_X = train_data[:,1:]\n",
    "test_X = test_data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals in test-data: 187708.0\n",
      "Comparison of [o]riginal and [a]djusted predictions:\n",
      " - [o]Signals read: 150915.0 \n",
      " - [a]Signals read: 191061 \n",
      " -- Difference: -40146.0 \n",
      " - [o]Correct labels: 412973 | signals: 100798 | background: 312175 \n",
      " ----- wrong signals: 86910 | background: 50117 \n",
      " - [a]Correct labels: 412675 | signals: 120722 | background: 291953 \n",
      " ----- wrong signals: 66986 | background: 70339 \n",
      " -- Difference labels: -298 | signals: 19924 | background: -20222 \n",
      " - [o]AMS: 2.8303462628376184 \n",
      " - [a]AMS: 2.8937862066934925 (threshold = 0.434343434343 )\n",
      " -- Difference: -0.06343994385587415 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predProb,pred = logisticReg(\n",
    "    train_X,train_labels,\n",
    "    test_X,\n",
    "    test_labels)[0:2];\n",
    "fullEvaluation(predProb,pred,test_weights,test_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "private rank #1485!\n",
    "\n",
    "We should use more features, but also get rid of too noisy ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb.createSolutionFile(test_eventList,predProb[:,1],0.43,\"F:\\BA_git\\Data\\Solutions\\solution_logReg_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_train_X = np.copy(train_X)\n",
    "norm_test_X = np.copy(test_X)\n",
    "\n",
    "for i in range(0,(len(header)-1)):\n",
    "    norm_train_X[:,i] /= np.mean(np.abs(train_X[:,i]),axis=0)\n",
    "    norm_test_X[:,i] /= np.mean(np.abs(test_X[:,i]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals in test-data: 187708.0\n",
      "Comparison of [o]riginal and [a]djusted predictions:\n",
      " - [o]Signals read: 150363.0 \n",
      " - [a]Signals read: 203480 \n",
      " -- Difference: -53117.0 \n",
      " - [o]Correct labels: 412811 | signals: 100441 | background: 312370 \n",
      " ----- wrong signals: 87267 | background: 49922 \n",
      " - [a]Correct labels: 411582 | signals: 126385 | background: 285197 \n",
      " ----- wrong signals: 61323 | background: 77095 \n",
      " -- Difference labels: -1229 | signals: 25944 | background: -27173 \n",
      " - [o]AMS: 2.848508104990537 \n",
      " - [a]AMS: 2.903120098938839 (threshold = 0.414141414141 )\n",
      " -- Difference: -0.05461199394830185 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predProb,pred = logisticReg(\n",
    "    norm_train_X,train_labels,\n",
    "    norm_test_X,\n",
    "    test_labels)[0:2];\n",
    "fullEvaluation(predProb,pred,test_weights,test_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb.createSolutionFile(test_eventList,predProb[:,1],0.41,\"F:\\BA_git\\Data\\Solutions\\solution_logReg_test_normed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featList = ['DER_mass_MMC','DER_mass_transverse_met_lep','DER_mass_vis']\n",
    "(new_header,new_test_data,new_test_weights,new_test_labels) = kD.getCustomDataSet(featList,kSet = \"v\")\n",
    "(new_header,new_train_data,new_train_weights,new_train_labels) = kD.getCustomDataSet(featList,kSet = \"t\")\n",
    "predProb,pred = logisticReg(\n",
    "    new_train_data,new_train_labels,\n",
    "    new_test_data, new_test_labels);\n",
    "fullEvaluation(predProb,pred,new_test_weights,new_test_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featList = kD.getFeatureListNoErrors()\n",
    "(new_header,new_test_data,new_test_weights,new_test_labels) = kD.getCustomDataSet(featList,kSet = 'b')\n",
    "(new_header,new_train_data,new_train_weights,new_train_labels) = kD.getCustomDataSet(featList,kSet = \"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_X = new_test_data[:,1:]\n",
    "test_weights = new_test_weights\n",
    "test_labels = new_test_labels\n",
    "\n",
    "train_X = new_train_data[:,1:]\n",
    "train_labels = new_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predProb,pred = logisticReg(\n",
    "    train_X,train_labels,\n",
    "    test_X, test_labels);\n",
    "fullEvaluation(predProb,pred,new_test_weights,new_test_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featList = [\"DER_mass_MMC\",\n",
    "            \"DER_mass_transverse_met_lep\",\n",
    "            \"DER_deltaeta_jet_jet\",\n",
    "            \"DER_met_phi_centrality\",\n",
    "            \"DER_pt_ratio_lep_tau\"]\n",
    "(new_header,new_test_data,new_test_weights,new_test_labels) = kD.getCustomDataSet(featList,kSet = 'v')\n",
    "(new_header,new_train_data,new_train_weights,new_train_labels) = kD.getCustomDataSet(featList,kSet = \"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = new_test_data[:,1:]\n",
    "test_weights = new_test_weights\n",
    "test_labels = new_test_labels\n",
    "\n",
    "train_X = new_train_data[:,1:]\n",
    "train_labels = new_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predProb,pred = logisticReg(\n",
    "    train_X,train_labels,\n",
    "    test_X, test_labels);\n",
    "fullEvaluation(predProb,pred,new_test_weights,new_test_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
