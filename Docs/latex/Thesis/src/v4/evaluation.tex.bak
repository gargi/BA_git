The evaluation of a single submission to the challenge is related to the common practice in particle physics to rate a discovery by its statistical significance, in this case 

%hier evtl mehr Ã¼ber die Entstehung?

\begin{equation}\label{eq:Z}
	Z = \sqrt{2 \left(n \ln{\left( \frac{n}{\mu_b} \right)} -
	n + \mu_b \right)}
\end{equation}

where $n$ is the total number of observed events and $\mu_b$ is the expected number of background-events.\\
Often in particle physics a significance of at least Z=5 (a five-sigma effect) is regarded as sufficient to claim a discovery \cite{higgsPaper}.

By estimating $n=s+b$ and $mu_b = b$ in Eq. \eqref{eq:Z}, we get the $Approximate$ $Median$ $Significance$ (AMS)

\begin{equation}\label{eq:AMS_1}
	AMS = \sqrt{2 \left( \left( s+b \right) \ln{ \left(1+ \frac{s}
	{b}  \right)} - s \right)}
\end{equation}

which is used by high-energy physicists for optimizing the selection region for stronger discovery significance \cite{higgsPaper}. 

For the challenge, a regularization-term $b_{reg}$ was introduced as an artificial shift to $b$ to decrease variance of the AMS, as this makes it easier to compare the participants if the optimal signal region was small. "The value $b_{reg}=10$ was determined using preliminary experiments." \cite{higgsPaper}

This addition to Eq. \eqref{eq:AMS_1} makes the final evaluation-formula complete:

\begin{equation}\label{eq:AMS_2}
	AMS_2 = \sqrt{2 \left( \left( s+b+b_{reg} \right) \ln{ \left(1+ \frac{s}
	{b+b_{reg}}  \right)} - s \right)}
\end{equation}

For simplicity, we will call it just AMS, as Eq. \eqref{eq:AMS_1} will not have further appearances in this thesis.
Fig. \ref{fig:amsFlow} gives a visual representation of the calculation.
\begin{center}
	\begin{figure}[h]
		\includegraphics[width=\textwidth]{images/AMS-flowchart.png}
		\caption{Flowchart describing AMS calculation for leaderboards}
		\label{fig:amsFlow}
	\end{figure}
\end{center}

\subsubsection{The leaderboard}
In Kaggle-Challenges, competitors are ranked in a leaderboard, rank 1 is the participant who submitted a solution which achieved the best score on the evaluation used in this challenge, in our case the AMS \eqref{eq:AMS_2}. To prevent participants from simply training algorithms on optimizing the leaderboard-score, Kaggle uses a so-called \textit{public} and \textit{private leaderboard}, which use different data from the test set to generate the AMS. The weights were normalized with respect to the number of events used for computing the public and private score, in our dataset \cite{higgsData} this information is given by the features \textit{KaggleSet} and \textit{KaggleWeight} so it is possible to compute these scores.

%%grafik um Aufteilung der bereits bewerteten daten zu zeigen.

During the challenge, the public leaderboard is visible to any visitor of Kaggle, so participants are able to get an evaluation of their submitted solution and work on better classification for a higher rank.
After reaching the \textit{final submission deadline}, the private leaderboard is accessible, which shows the final ranking of the challenge and the differences to the public leaderboard. Only the private rank is relevant for winning the challenge. Fig. \ref{fig:leaderboards} visualizes the final rankings of public and private leaderboards\footnote{data was accessed from \cite{higgsChallenge} with a simple python-script}. We notice several big differences in public and private rank of the same submission, a possible sign of overfitting the classifier. In Chap. \ref{ch:disc} the variance of the leaderboards will be studied further, for now we conclude to use the public AMS to evaluate our own classification-approaches. This enables better insight to what might cause the differences.

%compare public and private LB (graphic analysis on forums)
\begin{figure}[h]
	\includegraphics[width=\textwidth]{images/privateVSpublic}
	\caption{Compared rankings of the public and private leaderboard}
	\label{fig:leaderboards}
\end{figure}




%\subsubsection{Alternative objective functions}
%For classification, a data scientist wants to train a classifier on an \textit{objective function}. Properties of the AMS (like using the logarithm) make it difficult to use it as objective function, some alternatives were proposed by the challenge-creators \cite{higgsPaper} and some challenge-participants via the Kaggle-Forum %\cite{higgsForum}
%
%\begin{itemize}
%	\item alternative objective function: $ \frac{s}{\sqrt{b}} $
%	\begin{itemize}
%		\item only valid when $s \ll b \ and \ b \gg 1$
%	\end{itemize}
%	\item  weighted AUC \cite{diaz14}
%\end{itemize}