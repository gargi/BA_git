The evaluation of a single submission file to the challenge is based on the previously mentioned \emph{significance level}.
We define the \emph{significance}

\begin{equation}\label{eq:Z}
	Z = \sqrt{2 \left(n \ln{\left( \frac{n}{\mu_b} \right)} -
	n + \mu_b \right)} \mathrm{\hspace{1em},}
\end{equation}

where $n$ is the total number of observed events and bigger than $\mu_b$, which is the expected number of events produced by background effects.

In other words, we investigate a region in feature space and \emph{expect} a number $\mu_b$ of events. The number $n$ is what we \emph{actually} observe in this region. In particle physics, a significance of at least $Z=5$, called a \emph{five-sigma effect}, is regarded as sufficient to claim a discovery . This is equivalent to the previously stated \emph{significance level} $p = 2.87 \times 10^{-7}$ \cite{higgsPaper}.

We can substitute $n$ with $s+b$ and $\mu_b$ with $b$ and transform Eq. \eqref{eq:Z} to the \emph{Approximate Median Significance} (AMS)

\begin{equation}\label{eq:AMS_'}
	\mathrm{AMS'} = \sqrt{2 \left( \left( s+b \right) \ln{ \left(1+ \frac{s}
	{b}  \right)} - s \right)} \mathrm{\hspace{1em},}
\end{equation}

which resembles an estimation function that is used by high-energy physicists for optimizing the selection region for stronger discovery significance \cite{higgsPaper}. 

For the challenge, a regularization-term $b_{reg}$ was introduced as an artificial shift to $b$ to decrease variance of the AMS, as this makes it easier to compare the participants if the optimal signal region was small. The challenge's documentation provides no further information on the choice $b_{reg}=10$ \cite{higgsPaper}.

This addition to Eq. \eqref{eq:AMS_'} makes the final evaluation-formula complete:

\begin{equation}\label{eq:AMS}
	\mathrm{AMS} = \sqrt{2 \left( \left( s+b+b_{reg} \right) \ln{ \left(1+ \frac{s}
	{b+b_{reg}}  \right)} - s \right)}
\end{equation}

For simplicity, we will call it just AMS, as Eq. \eqref{eq:AMS_'} will not have further appearances in this thesis.

\subsubsection{AMS as Objective Function in Classification}
In data classification, an \emph{objective function} is a tool to estimate the accuracy of a fitted classifier. To find a good classifier we directly try to optimize the AMS.

If we partially derive Eq. \eqref{eq:AMS} with respect to $s$, we get

\begin{equation}\label{eq:AMS_der}
	\frac{\partial}{\partial s} \mathrm{AMS} = 
	\frac{\frac{s + b + b_{reg}}
	{ ( b + b_{reg} ) \left( \frac{s}{b + b_reg} + 1 \right)}
	+ \ln \left( \frac{s}{b + b_reg} + 1 \right) - 1}
	{ \sqrt{2 \left( ( s + b + b_{reg} ) \ln{ \left( 1 +  \frac{s}{b+b_{reg}} \right)} - s \right)}} \mathrm{\hspace{1em}.}
\end{equation}

The complexity of Eq. \eqref{eq:AMS_der} is the reason why most participants of the challenge avoided the AMS as a primary objective function. After the actual prediction, which is made by the classifier fitted to another objective, the events are ranked according to their likelihood of being a signal. The AMS can now be used to determine an optimal decision threshold for the final classification. For most submissions, given their ranking works correctly, classifying the top 14\% of most likely events as signal resulted in optimal AMS \cite{cowa14}. Many participants simply substituted the AMS with common objective functions like \emph{squared error} that are computational efficient. Some investigated AMS further and found related functions with beneficial properties, like easier derivation \cite{kotl14,mack14,diaz14}.