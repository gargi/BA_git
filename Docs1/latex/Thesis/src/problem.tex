\subsection{The classification problem}\label{sec:prob}
We use the formal description of the challenge as in \cite{higgsPaper}.\\
Let $D = {(x_i,y_i,w_i)}, \ i \ \epsilon \ \{1,\ldots,n\}$ be the training sample with $n$ events, where:

\begin{itemize}
	\item $x_i \ \epsilon \ \mathbb{R}^{d}$ is a $d$-dimensional vector
	\item $y_i \ \epsilon$ \{b,s\} is the label
	\item and $w_i \ \epsilon \ \mathbb{R}^{+}$ is a non-negative weight.
\end{itemize}

The sum of signal weights
$$S = \sum_{y_i = s} w_i$$
and the sum of background weights
$$B = \sum_{y_i = b} w_i$$
represent the \emph{expected total number} of signal and background events, during the time of actual data recording.

Let a function $$g: \mathbb{R}^{d} \rightarrow \{b,s\}$$
be a binary classifier.
The set $$G_s = \{x : g(x) = s \}$$ is called the \emph{selection region}.

Our task is to find a function \emph{g} that maximizes the AMS, that we introduce in the next section.\\
For a given classifier \emph{g} we maintain an \emph{index set} 
$ \hat{G}_s = \{i : g(x_i) = s \} $ of training points that $g$ classifies as signal and an \emph{index set} $ \hat{G}_b = \{i : g(x_i) \neq s \} $. By definition each point can only be one index set, i.e. ($\hat{G}_s \cap \hat{G}_b = \emptyset$).

The index set can be turned into a submission file for the challenge, but requires to fit the following format.

\begin{verbatim}
EventId,RankOrder,Class
350000,2,b
350001,54493,s
...
899999,32455,b
\end{verbatim}

All events must have a prediction \texttt{b} or \texttt{s}. \texttt{RankOrder} shall state the probability of an event being the signal \texttt{s}, compared to all other events, e.g. rank \texttt{550000} is being considered as the most signal-like event. However, predicting the right event ranking was not necessary for the challenge.